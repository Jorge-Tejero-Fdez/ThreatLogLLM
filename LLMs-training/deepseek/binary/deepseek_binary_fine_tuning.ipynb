{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK DEEPSEEK - BINARY CLASSIFICATION (FINE-TUNING)\n",
    "\n",
    "This notebook evaluates the DeepSeek LLM using fine-tuning prompting for binary classification, distinguishing between normal and attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objectives\n",
    "\n",
    "The objective of this notebook is to evaluate the performance of the DeepSeek LLM in a **fine-tuned binary classification** setting.\n",
    "\n",
    "Specifically, this notebook aims to:\n",
    "- Assess the model's ability to distinguish between **normal** and **attack** after being fine-tuned on labeled examples.\n",
    "- Analyze its predictions and evaluate its suitability for binary threat detection tasks in IoT systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. IMPORTS AND SETUP\n",
    "Import the required python libraries, preprocessing, training (fine-tuning) and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/TFM/threatlogllm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pandas, json, re and os imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "# visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# imports for LLM training\n",
    "from datasets import Dataset, DatasetDict\n",
    "from huggingface_hub import interpreter_login\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "# imports for evaluation (sklearn)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "# tqdm import\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Login to Hugging Face Hub\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PREPARE DATASET\n",
    "\n",
    "The dataset is split into 70% for training, 15% for validation, and 15% for testing. The model is fine-tuned on the training set while using the validation set to monitor performance during training. After fine-tuning, the final evaluation is performed on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n### Instruction:\\nYou are a cybersecurity expert specializing in IoT security. Your task is to analyze network logs and determine whether the given log data indicates a potential attack. Only provide a response if this log data indicates a potential attack or normal traffic.\\n### Question:\\n- The length of the DNS query is: 0\\n- The MQTT protocol name used is: 0\\n- The MQTT message type is: 0\\n- The MQTT topic is: 0\\n- The MQTT connection acknowledgment flags are: 0\\n- TCP options set in the packet are: 0\\n- TCP destination port is: 53316.0\\n### Response:\\n<think>\\nThis log data is normal traffic.\\n</think>'}\n"
     ]
    }
   ],
   "source": [
    "# Define file path\n",
    "file_path = \"../../../data/prompts/binary_instructions.jsonl\"\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "\n",
    "# Read JSONL file line by line\n",
    "samples = []\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        sample = json.loads(line.strip())  # Load each line as a JSON object\n",
    "        samples.append({\"text\": sample[\"Prompt\"]})  # Extract the prompt field\n",
    "\n",
    "# Convert into Hugging Face Dataset format\n",
    "dataset_dict = {\"full\": Dataset.from_list(samples)}\n",
    "dataset = DatasetDict(dataset_dict)\n",
    "\n",
    "# Verify first example\n",
    "print(dataset[\"full\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 8400\n",
      "Validation Samples: 1800\n",
      "Test Samples: 1800\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the dataset\n",
    "dataset = dataset[\"full\"].shuffle(seed=42)\n",
    "\n",
    "# Split dataset into train (70%), validation (15%), test (15%)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "\n",
    "# Ensure the split sizes are correct\n",
    "train_dataset = dataset.select(range(train_size))\n",
    "val_dataset = dataset.select(range(train_size, train_size + val_size))\n",
    "test_dataset = dataset.select(range(train_size + val_size, len(dataset)))\n",
    "\n",
    "# Print sizes\n",
    "print(f\"Train Samples: {len(train_dataset)}\")\n",
    "print(f\"Validation Samples: {len(val_dataset)}\")\n",
    "print(f\"Test Samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PREPARE LLM\n",
    "\n",
    "Load the DeepSeek language model from Unsloth with specific configuration parameters for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4060 Laptop GPU. Max memory: 7.996 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "# Define model loading parameters\n",
    "max_seq_length = 2048 \n",
    "dtype = None \n",
    "load_in_4bit = True\n",
    "\n",
    "# Load the DeepSeek LLM with Unsloth's FastLanguageModel utility\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n",
       "        (layers): ModuleList(\n",
       "          (0): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "          (1): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "          (2-31): 30 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model's config\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,  \n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\",\n",
    "        \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,  \n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",  \n",
    "    random_state=3407,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")\n",
    "\n",
    "# Reach the model for training\n",
    "FastLanguageModel.for_training(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PREPARE DATASET WITH EOS\n",
    "\n",
    "In this section, each sample in the dataset is formatted to include an end-of-sentence (EOS) token.  \n",
    "This ensures proper termination of sequences during training and improves model understanding of prompt boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8400/8400 [00:00<00:00, 69015.26 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1800/1800 [00:00<00:00, 98328.33 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1800/1800 [00:00<00:00, 58669.80 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
      "### Instruction:\n",
      "You are a cybersecurity expert specializing in IoT security. Your task is to analyze network logs and determine whether the given log data indicates a potential attack. Only provide a response if this log data indicates a potential attack or normal traffic.\n",
      "### Question:\n",
      "- The length of the DNS query is: 0.0\n",
      "- The MQTT protocol name used is: 0.0\n",
      "- The MQTT message type is: 0.0\n",
      "- The MQTT topic is: 0.0\n",
      "- The MQTT connection acknowledgment flags are: 0.0\n",
      "- TCP options set in the packet are: 0\n",
      "- TCP destination port is: 0.0\n",
      "### Response:\n",
      "<think>\n",
      "This log data is an attack!!.\n",
      "</think><ï½œendâ–ofâ–sentenceï½œ>\n"
     ]
    }
   ],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token  # Ensure each training sample has an EOS token\n",
    "\n",
    "# Formatting function to structure data properly\n",
    "def formatting_prompts_func(examples):\n",
    "    texts = []\n",
    "    for entry in examples[\"text\"]:  # \"text\" is the key in our dataset\n",
    "        text = entry + EOS_TOKEN  # Append EOS token\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}\n",
    "\n",
    "# Apply formatting\n",
    "train_dataset = train_dataset.map(formatting_prompts_func, batched=True)\n",
    "val_dataset = val_dataset.map(formatting_prompts_func, batched=True)\n",
    "test_dataset = test_dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "# Print an example formatted sample\n",
    "print(train_dataset[\"text\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. INITIALIZE THE SFTTrainer FOR FINE-TUNING\n",
    "\n",
    "This section initializes the `SFTTrainer` with the model, tokenizer, and prepared datasets.  \n",
    "It sets training arguments such as learning rate, batch size, evaluation strategy, and checkpointing.  \n",
    "The model will be fine-tuned using supervised learning and validated on the evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8400/8400 [00:03<00:00, 2647.08 examples/s]\n",
      "Map (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1800/1800 [00:01<00:00, 1048.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the trainer, with SFTTrainer and TrainingArguments\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=2,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=5,\n",
    "        max_steps=500,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"outputs_deepseek\",\n",
    "        eval_strategy=\"steps\", \n",
    "        save_strategy=\"steps\", \n",
    "        save_total_limit=2,  \n",
    "        metric_for_best_model=\"eval_loss\",  \n",
    "        load_best_model_at_end=True,  \n",
    "        greater_is_better=False, \n",
    "    ),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # Stop if loss doesn't improve in 3 evaluations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. TRAINING MODEL\n",
    "\n",
    "In this section, the model is fine-tuned for up to 500 steps.  \n",
    "Evaluation is performed on the validation set every 10 steps, and early stopping is applied if no improvement is observed for 3 consecutive evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 8,400 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 500\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/500 4:47:47 < 12:02, 0.03 it/s, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.199800</td>\n",
       "      <td>0.435549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.152001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.104194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.095364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.092731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.087584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.083816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.084048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.081103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.079973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.080107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.079102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.078639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.079428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.078200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.077108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.075780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.077344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.075983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.074713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.074880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.062800</td>\n",
       "      <td>0.073822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.074350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.073678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.073846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.073507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.072959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.073388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.072183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.071128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.071936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.090600</td>\n",
       "      <td>0.071002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.087800</td>\n",
       "      <td>0.070931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.070983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>0.070503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.070552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.070232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.070161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.069237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.069341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.068945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.069183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.068254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.068537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.068229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.059700</td>\n",
       "      <td>0.068821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>0.068478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.068393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n",
      "Could not locate the best model at outputs_deepseek/checkpoint-450/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n"
     ]
    }
   ],
   "source": [
    "# Start fine-tuning\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fine-tuned-model/deepseek_binary_finetuned_model/tokenizer_config.json',\n",
       " 'fine-tuned-model/deepseek_binary_finetuned_model/special_tokens_map.json',\n",
       " 'fine-tuned-model/deepseek_binary_finetuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save fine-tuned model and tokenizer\n",
    "trainer.save_model(\"fine-tuned-model/deepseek_binary_finetuned_model\")  # Saves model weights\n",
    "tokenizer.save_pretrained(\"fine-tuned-model/deepseek_binary_finetuned_model\")  # Saves tokenizer config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. COMPUTE PREDICTIONS\n",
    "\n",
    "In this section, predictions are generated using the LLM (`predictions_binary`) and stored in a list. The corresponding true labels are also collected in a separate list (`actual_labels_binary`). \n",
    "\n",
    "Both lists will be used later to compute evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure labels are properly converted to binary\n",
    "def label_to_binary(response):\n",
    "    response = response.lower()\n",
    "    if \"attack\" in response:\n",
    "        return 1  # Attack detected\n",
    "    return 0  # Normal traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1800/1800 [39:46<00:00,  1.33s/sample]\n"
     ]
    }
   ],
   "source": [
    "# Ensures optimized inference\n",
    "FastLanguageModel.for_inference(model) \n",
    "\n",
    "# Initialize lists to store actual vs predicted labels\n",
    "predictions_binary = []\n",
    "actual_labels_binary = []\n",
    "\n",
    "# Iterate over test dataset with tqdm for progress tracking\n",
    "for sample in tqdm(test_dataset, desc=\"Processing Samples\", unit=\"sample\"):\n",
    "    full_text = sample[\"text\"]\n",
    "\n",
    "    # Extract only the log entry (remove the response part)\n",
    "    input_text = re.split(r\"### Response:\", full_text, maxsplit=1)[0].strip()\n",
    "\n",
    "    # Extract actual label correctly (but don't pass it to the model)\n",
    "    actual_label = label_to_binary(full_text.split(\"### Response:\")[1].strip()) if \"### Response:\" in full_text else label_to_binary(\"Normal\")\n",
    "\n",
    "    # Tokenize input (ONLY the log entry)\n",
    "    inputs = tokenizer([input_text], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate response\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_new_tokens=200,  \n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    # Decode prediction and convert to binary\n",
    "    predicted_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
    "    predicted_label = label_to_binary(predicted_text.split(\"### Response:\")[1].strip())\n",
    "\n",
    "    # Store results\n",
    "    predictions_binary.append(predicted_label)\n",
    "    actual_labels_binary.append(actual_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compute Evaluation Metrics\n",
    "\n",
    "In this section, standard evaluation metrics are computed to assess the model's performance. These include Accuracy, Precision, Recall, F1-Score, and the Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Perform evaluation\n",
    "accuracy = accuracy_score(actual_labels_binary, predictions_binary)\n",
    "precision = precision_score(actual_labels_binary, predictions_binary, average=\"binary\", pos_label=1)\n",
    "recall = recall_score(actual_labels_binary, predictions_binary, average=\"binary\", pos_label=1)\n",
    "f1 = f1_score(actual_labels_binary, predictions_binary, average=\"binary\", pos_label=1)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(actual_labels_binary, predictions_binary)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "cm_df = pd.DataFrame(cm, index=[\"Actual Attack\", \"Actual Normal\"], columns=[\"Predicted Attack\", \"Predicted Normal\"])\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', linewidths=0.5)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix - Deepseek Binary fine-tuned\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "threatlogllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
